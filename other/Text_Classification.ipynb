{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbNBWhBLjFiR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ikojhBrjFiU"
      },
      "outputs": [],
      "source": [
        "import nltk \n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHIuTBs2jFiV",
        "outputId": "9f487daa-2c5b-4220-d5ad-8bab862b73e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5572, 5)\n",
            "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')\n",
            "    v1                                                 v2 Unnamed: 2  \\\n",
            "0  ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1  ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n"
          ]
        }
      ],
      "source": [
        "filename = 'spam.csv'\n",
        "df = pd.read_csv(filename,encoding = 'latin-1')\n",
        "print(df.shape)\n",
        "print(df.columns)\n",
        "print(df.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrXlJDWejFiW",
        "outputId": "49548d61-79f2-4a2e-9263-1981914b3a6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5572, 5)\n",
            "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...']\n",
            "['ham']\n"
          ]
        }
      ],
      "source": [
        "data = df.values #numpy \n",
        "print(data.shape)\n",
        "lines = data[:,1]# X\n",
        "labels = data[:,0]# y\n",
        "print(lines[:1])\n",
        "print(labels[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d12Q20JJjFiW",
        "outputId": "22dc6628-8e59-47ab-d58e-cbff225b3a55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Go', 'until', 'jurong', 'point', ',', 'crazy', '..', 'Available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', '...', 'Cine', 'there', 'got', 'amore', 'wat', '...']\n"
          ]
        }
      ],
      "source": [
        "# tách từ trong từng câu \n",
        "sentences = [nltk.word_tokenize(sent) for sent in lines]\n",
        "print(sentences[0])\n",
        "# lấy feature cho câu "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9Uy0MisjFiX",
        "outputId": "3fa72d98-ec41-4921-a2a4-93d90d9d49c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "<frozen importlib._bootstrap>:228: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.9\n",
            "<frozen importlib._bootstrap>:228: RuntimeWarning: builtins.type size changed, may indicate binary incompatibility. Expected 880, got 864\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "# kiểm tra từ điểm tạo trong tokenizer\n",
        "#print(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tfAVKcZjFiY",
        "outputId": "bc3fa2ea-f98a-4597-9b06-e642922cd03b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 1. 1. 0.]\n",
            " [0. 0. 1. ... 0. 0. 1.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n",
            "(5572, 9444)\n",
            "5572\n"
          ]
        }
      ],
      "source": [
        "#texts_to_matrix(tokenizer, texts, mode = c(\"binary\", \"count\", \"tfidf\", \"freq\"))\n",
        "X = tokenizer.texts_to_matrix(sentences,mode='binary')\n",
        "print(X)\n",
        "print(X.shape)\n",
        "print(len(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMifQs8NjFiY",
        "outputId": "1323f897-e718-4f1c-ae0a-36139c5dedf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4457, 9444)\n",
            "(1115, 9444)\n"
          ]
        }
      ],
      "source": [
        "# chia tập train và tập test \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, \n",
        "                                            test_size=0.2, random_state=0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duSaHfc8jFiZ",
        "outputId": "ee78c93a-049f-419a-fbae-4e78d9b67d46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.99      0.99       949\n",
            "        spam       0.93      0.92      0.92       166\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.96      0.95      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB \n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model_NB = MultinomialNB()#khai báo model \n",
        "\n",
        "model_NB = model_NB.fit(X_train,y_train) #learning \n",
        "\n",
        "y_pred = model_NB.predict(X_test) # test \n",
        "\n",
        "print(classification_report(y_test,y_pred)) #tính accuracy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU0F8CKKjFia",
        "outputId": "b4c481ab-ad82-480e-ce81-ef60370c621d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      1.00      0.99       949\n",
            "        spam       0.97      0.88      0.92       166\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.98      0.94      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "model = svm.SVC(kernel=\"linear\")\n",
        "\n",
        "model = model.fit(X_train,y_train) #learning \n",
        "\n",
        "y_pred = model.predict(X_test) # test \n",
        "\n",
        "print(classification_report(y_test,y_pred)) #tính accuracy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLL1ImqkjFib",
        "outputId": "7275aace-2124-453c-a99e-d2d22a7771b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'FA', 'Cup', 'final', 'tkts', '21st', 'May', '2005']\n",
            "[[0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "input_sent = 'Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005'\n",
        "# dự đoán?\n",
        "tokens = nltk.word_tokenize(input_sent)\n",
        "print(tokens)\n",
        "X_input = tokenizer.texts_to_matrix([tokens],mode='binary')\n",
        "print(X_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ptT9J8YjFib",
        "outputId": "0385076a-f776-4066-a3ce-460bb194fa7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['spam']\n"
          ]
        }
      ],
      "source": [
        "y_pred = model_NB.predict(X_input)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe20qg7-jFic"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression  \n",
        "model_LR = LogisticRegression()\n",
        "model_LR = model_LR.fit(X_train,y_train)\n",
        "y_pred = model_LR.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwcGrqSqjFic",
        "outputId": "6ecc9040-cf17-4c28-ef4b-0782b6adbfab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      1.00      0.99       949\n",
            "        spam       0.99      0.89      0.94       166\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.98      0.94      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWpCWt3ljFic"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}