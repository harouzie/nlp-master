{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kFCKHDUleL5R"
      },
      "outputs": [],
      "source": [
        "!pip install datasets -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6Ys_UxT9eB5K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Attention, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import string\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mhMwSy-re8z4"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'\\t', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EkQadLf9gvu2"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqAttention(Model):\n",
        "    def __init__(self, num_encoder_tokens, num_decoder_tokens, latent_dim):\n",
        "        super(Seq2SeqAttention, self).__init__()\n",
        "        self.encoder_embed = Embedding(num_encoder_tokens, latent_dim)\n",
        "        self.encoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "        self.decoder_embed = Embedding(num_decoder_tokens, latent_dim)\n",
        "        self.decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "        self.attention_layer = Attention()\n",
        "        self.concat_layer = Concatenate(axis=-1)\n",
        "        self.decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        encoder_inputs, decoder_inputs = inputs\n",
        "        encoder_embed = self.encoder_embed(encoder_inputs)\n",
        "        encoder_outputs, state_h, state_c = self.encoder_lstm(encoder_embed)\n",
        "        encoder_states = [state_h, state_c]\n",
        "\n",
        "        decoder_embed = self.decoder_embed(decoder_inputs)\n",
        "        decoder_outputs, _, _ = self.decoder_lstm(decoder_embed, initial_state=encoder_states)\n",
        "\n",
        "        attention_result = self.attention_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "        decoder_concat_input = self.concat_layer([decoder_outputs, attention_result])\n",
        "\n",
        "        decoder_outputs = self.decoder_dense(decoder_concat_input)\n",
        "        return decoder_outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "83a8c42bc62841e397467158d5d0041a",
            "350e0d4a9ffa4cdbb52bb0d41f2eb274",
            "cdface107f044f58866c323cbf51d309",
            "3f4c3485897843309856f23b6c3ee35a",
            "a9c5fd811c714e9cb4af62e3e7db725f",
            "fa65701de3dc472c864d461aad01eb49",
            "2ec06499cc87491bbc69b7042054c770",
            "99880db6c49e4e1d913010070b660194",
            "e01f8055681e4e0b9ba86136df6e8282",
            "4add06335291454986ba065002489ccc",
            "b2d703e031ac406a932d6434ef11ea08"
          ]
        },
        "id": "K1J0iBdge82o",
        "outputId": "fa4eb4e5-823d-43e9-fe6c-4a322a2266d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset xsum (/root/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83a8c42bc62841e397467158d5d0041a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# dataset = load_dataset(\"xsum\", \"3.0.0\")\n",
        "# train_dataset = dataset[\"train\"]\n",
        "# val_dataset = dataset[\"validation\"]\n",
        "# test_dataset = dataset[\"test\"]\n",
        "train_dataset, dev_dataset, test_dataset = load_dataset(\"xsum\",split=['train[:10000]', 'validation[:1000]', 'test[:1000]'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXGbZ_M228PA",
        "outputId": "3da0ffc8-df17-4d24-a21f-53fe4beeea95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['document', 'summary', 'id'],\n",
              "     num_rows: 10000\n",
              " }), Dataset({\n",
              "     features: ['document', 'summary', 'id'],\n",
              "     num_rows: 1000\n",
              " }), Dataset({\n",
              "     features: ['document', 'summary', 'id'],\n",
              "     num_rows: 1000\n",
              " }))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset, dev_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "riRX_CAQ0CaZ"
      },
      "outputs": [],
      "source": [
        "documents = train_dataset[0][\"document\"]\n",
        "summary = train_dataset[0][\"summary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WkJkQEmhkpR9"
      },
      "outputs": [],
      "source": [
        "train_stories = [\n",
        "    {\n",
        "        'document': clean_text(example['document']),\n",
        "        'summary': clean_text(example['summary'])\n",
        "    } \n",
        "    for example in train_dataset\n",
        "]\n",
        "\n",
        "val_stories = [\n",
        "    {\n",
        "        'document': clean_text(example['document']), \n",
        "        'summary': clean_text(example['summary'])\n",
        "    } \n",
        "    for example in dev_dataset\n",
        "]\n",
        "\n",
        "test_stories = [\n",
        "    {\n",
        "        'document': clean_text(example['document']), \n",
        "        'summary': clean_text(example['summary'])\n",
        "    } \n",
        "    for example in test_dataset\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAfxk1tpj1Yd",
        "outputId": "c74fcf5a-d5db-457f-998c-4824c557936b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training stories: 10000\n",
            "Validation stories: 1000\n",
            "Test stories: 1000\n"
          ]
        }
      ],
      "source": [
        "print(f'Training stories: {len(train_stories)}')\n",
        "print(f'Validation stories: {len(val_stories)}')\n",
        "print(f'Test stories: {len(test_stories)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s5FJ_eN_gpAq"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 100\n",
        "latent_dim = 256\n",
        "num_encoder_tokens = 1000  # Set this to the number of unique tokens in your input language\n",
        "num_decoder_tokens = 1000  # Set this to the number of unique tokens in your target language\n",
        "# Set your vocabulary size and maximum sequence length\n",
        "vocab_size = 10000\n",
        "max_seq_length = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yvufgnsG4dCi"
      },
      "outputs": [],
      "source": [
        "# Initialize tokenizers for documents and summary\n",
        "document_tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
        "summary_tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>', filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hzfJRmvx4efj"
      },
      "outputs": [],
      "source": [
        "# Fit the tokenizers on the training data\n",
        "document_tokenizer.fit_on_texts([story['document'] for story in train_stories])\n",
        "summary_tokenizer.fit_on_texts(['<start> ' + story['summary'] + ' <end>' for story in train_stories])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pOiwJQHc4iLH"
      },
      "outputs": [],
      "source": [
        "# Convert the text to sequences\n",
        "document_sequences = document_tokenizer.texts_to_sequences([story['document'] for story in train_stories + val_stories + test_stories])\n",
        "summary_sequences = summary_tokenizer.texts_to_sequences(['<start> ' + story['summary'] + ' <end>' for story in train_stories + val_stories + test_stories])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tqoxC44d5WpP"
      },
      "outputs": [],
      "source": [
        "mean_doc_len = np.mean([len(doc) for doc in document_sequences])\n",
        "mean_sum_len = np.mean([len(sum) for sum in summary_sequences])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_svmUDS37qiw",
        "outputId": "e7c96318-c2e9-4fcf-ecc5-e7677cb5460c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average length of doccument sequences is: 378.25 words\n",
            "Average length of summary sequences is: 23.45 words\n"
          ]
        }
      ],
      "source": [
        "print(f\"Average length of doccument sequences is: {mean_doc_len:.2f} words\")\n",
        "print(f\"Average length of summary sequences is: {mean_sum_len:.2f} words\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BKgG__oP4lmK"
      },
      "outputs": [],
      "source": [
        "# Pad the sequences\n",
        "encoder_input_data = pad_sequences(document_sequences, maxlen=max_seq_length, padding='post', truncating='post')\n",
        "decoder_input_data = pad_sequences(summary_sequences, maxlen=50, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFnpebv48JSn",
        "outputId": "1ac6d2c2-9f9b-4f1f-c1e0-ec60d522c7d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12000, 500)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder_input_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n944NJwT8nvI",
        "outputId": "6209c95a-82e0-427b-ac0f-f3a6bc5b7a10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12000, 50)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder_input_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2NqvWBf83B8",
        "outputId": "76a65a20-7d13-453d-c6f1-121615c8a6c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   4, 3296,   54, 1178,   25, 1853,  251,    2,  119,  962,   10,\n",
              "       1519,   10, 2680,   17, 1656,  555,   18, 1441, 2965,    3,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder_input_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AVOdctBPe85k"
      },
      "outputs": [],
      "source": [
        "# Shift the decoder target data by one timestep\n",
        "decoder_target_data = np.zeros_like(decoder_input_data)\n",
        "decoder_target_data[:, 0:-1] = decoder_input_data[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYrOZcec8ynT",
        "outputId": "9126eda5-675d-4464-b046-ff40ae0635ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12000, 50)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder_target_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klKTQj-G8_lU",
        "outputId": "b3d5a387-7a72-4ee2-f067-2bc2086aedb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3296,   54, 1178,   25, 1853,  251,    2,  119,  962,   10, 1519,\n",
              "         10, 2680,   17, 1656,  555,   18, 1441, 2965,    3,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder_target_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5ZdQtfwv49tg"
      },
      "outputs": [],
      "source": [
        "# Convert the target data to one-hot encoding\n",
        "decoder_target_data = to_categorical(decoder_target_data, num_classes=vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkP_i7UD9NVD",
        "outputId": "bc1df9dc-9e3d-479a-fd75-a632f0b264f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12000, 50, 10000)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder_target_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fsFPIQ89e88G"
      },
      "outputs": [],
      "source": [
        "model = Seq2SeqAttention(num_encoder_tokens, num_decoder_tokens, latent_dim)\n",
        "\n",
        "# Prepare the input and output tensors\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "outputs = model([encoder_inputs, decoder_inputs])\n",
        "\n",
        "# Create the final model with the input and output tensors\n",
        "model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE56zGLS1Wxu",
        "outputId": "8be43efe-9db9-4ee4-8617-0286cd6e2267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " seq2_seq_attention (Seq2SeqAtt  (None, None, 1000)  2075624     ['input_1[0][0]',                \n",
            " ention)                                                          'input_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,075,624\n",
            "Trainable params: 2,075,624\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7D72TNt00us",
        "outputId": "a1a61acf-0c6c-48ad-a959-2f654bbb077c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"seq2_seq_attention\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  256000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 multiple                  525312    \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     multiple                  256000    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               multiple                  525312    \n",
            "                                                                 \n",
            " attention (Attention)       multiple                  0         \n",
            "                                                                 \n",
            " concatenate (Concatenate)   multiple                  0         \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  513000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,075,624\n",
            "Trainable params: 2,075,624\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.get_layer(\"seq2_seq_attention\").summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCpRrDHGe8-w"
      },
      "outputs": [],
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=2,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xH8t10ie9B2"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqInference:\n",
        "    def __init__(self, model, document_tokenizer, summary_tokenizer, max_seq_length):\n",
        "        self.model = model\n",
        "        self.document_tokenizer = document_tokenizer\n",
        "        self.summary_tokenizer = summary_tokenizer\n",
        "        self.max_seq_length = max_seq_length\n",
        "\n",
        "    def generate_summary(self, input_text):\n",
        "        # Tokenize and pad the input text\n",
        "        input_seq = self.document_tokenizer.texts_to_sequences([input_text])\n",
        "        input_seq = pad_sequences(input_seq, maxlen=self.max_seq_length, padding='post', truncating='post')\n",
        "        \n",
        "        # Initialize the decoder input with the <start> token\n",
        "        start_token = self.summary_tokenizer.word_index['<start>']\n",
        "        end_token = self.summary_tokenizer.word_index['<end>']\n",
        "        target_seq = np.zeros((1, self.max_seq_length))\n",
        "        target_seq[0, 0] = start_token\n",
        "\n",
        "        decoded_sentence = []\n",
        "        for i in range(1, self.max_seq_length):\n",
        "            # Get the model prediction\n",
        "            output_tokens = self.model.predict([input_seq, target_seq])[0, i - 1, :]\n",
        "\n",
        "            # Sample a token\n",
        "            sampled_token_index = np.argmax(output_tokens)\n",
        "            \n",
        "            # Check if the sampled token is the <end> token or not\n",
        "            if sampled_token_index == end_token:\n",
        "                break\n",
        "\n",
        "            # Add the sampled token to the decoded sentence\n",
        "            decoded_sentence.append(self.summary_tokenizer.index_word[sampled_token_index])\n",
        "\n",
        "            # Update the target sequence (of length 1)\n",
        "            target_seq[0, i] = sampled_token_index\n",
        "\n",
        "        return ' '.join(decoded_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVyk6-UVh2Rt"
      },
      "outputs": [],
      "source": [
        "inference = Seq2SeqInference(model, document_tokenizer, summary_tokenizer,, max_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eSQDK8ah2UZ"
      },
      "outputs": [],
      "source": [
        "input_text = \"Some example news article text.\"\n",
        "generated_summary = inference.generate_summary(input_text)\n",
        "print(\"Generated summary:\", generated_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3q3QDkoh2aN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "aiml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "python",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ec06499cc87491bbc69b7042054c770": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "350e0d4a9ffa4cdbb52bb0d41f2eb274": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa65701de3dc472c864d461aad01eb49",
            "placeholder": "​",
            "style": "IPY_MODEL_2ec06499cc87491bbc69b7042054c770",
            "value": "100%"
          }
        },
        "3f4c3485897843309856f23b6c3ee35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4add06335291454986ba065002489ccc",
            "placeholder": "​",
            "style": "IPY_MODEL_b2d703e031ac406a932d6434ef11ea08",
            "value": " 3/3 [00:02&lt;00:00,  2.04it/s]"
          }
        },
        "4add06335291454986ba065002489ccc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83a8c42bc62841e397467158d5d0041a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_350e0d4a9ffa4cdbb52bb0d41f2eb274",
              "IPY_MODEL_cdface107f044f58866c323cbf51d309",
              "IPY_MODEL_3f4c3485897843309856f23b6c3ee35a"
            ],
            "layout": "IPY_MODEL_a9c5fd811c714e9cb4af62e3e7db725f"
          }
        },
        "99880db6c49e4e1d913010070b660194": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9c5fd811c714e9cb4af62e3e7db725f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2d703e031ac406a932d6434ef11ea08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdface107f044f58866c323cbf51d309": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99880db6c49e4e1d913010070b660194",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e01f8055681e4e0b9ba86136df6e8282",
            "value": 3
          }
        },
        "e01f8055681e4e0b9ba86136df6e8282": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa65701de3dc472c864d461aad01eb49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
