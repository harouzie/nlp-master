{"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01acaeca4ff94a01a8fdd1d8edde0b40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cac07e0b30441e1ad4dc15bf04e2f68","placeholder":"​","style":"IPY_MODEL_6be7d09cb9c84a0190cee8f390ac63bb","value":"Map: 100%"}},"03df46fcd67e4ec9ace9ce7c2ac3b323":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_191feda3254f46529c4f47ea30193cb8","placeholder":"​","style":"IPY_MODEL_4b0406653341498a831110cc880c781c","value":"Map: 100%"}},"191feda3254f46529c4f47ea30193cb8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b42bee723ec4f9d9d19a1b6472fae7b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1daf4473a8b246b6b0929f16c613a8c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"250245c3a4ef4e5aba91157bd1bb4b70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"298eb90147cb4b06aae645c73d6821b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b67dba7b7094515b8712fa07c348f00":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e01fcbfb0434cff868267315ea45ed2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3159c26e83b142609e2c0b5a6fa044b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b67dba7b7094515b8712fa07c348f00","placeholder":"​","style":"IPY_MODEL_3faefa6665de40a38d1d61cbb8d95c5e","value":" 1000/1000 [00:06&lt;00:00, 83.91 examples/s]"}},"3a97e465628a4867b44b3abd4466aa97":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d5354f7e5614f5cbf50c02568f81c02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3faefa6665de40a38d1d61cbb8d95c5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4038594438a64677891b7661da373ab3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_efeecc4f77e049b7965dcb2562ba0c8c","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7063ac1e7c9747abaf8558c6fb498d85","value":1000}},"4b0406653341498a831110cc880c781c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cac07e0b30441e1ad4dc15bf04e2f68":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e5bcd700f8f4597a77c056015d88686":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_82fdd095aa8147cb80454ece668ffea2","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf153deb761947f1b148cda002103a05","value":10000}},"55b859e84fa44d6ba202aacb3e44ed2f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58d0f23171214dc4b9e8c29cae828fc7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bed23f445c6474eba498767461fbdd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7193a4ed14204de9b2220cf156cf6498","IPY_MODEL_4038594438a64677891b7661da373ab3","IPY_MODEL_3159c26e83b142609e2c0b5a6fa044b6"],"layout":"IPY_MODEL_cb7b123873c84ec5a0ce632f4cbc8efb"}},"648d2606a4cb4692acd93aaab2ea4167":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa0d5b481a5842179097bbe84e85cae7","IPY_MODEL_e68a6464e7af4492b6497afd60868881","IPY_MODEL_b01582666abd4a8982fa718aac453856"],"layout":"IPY_MODEL_77885cf419174691b00c2057238d6365"}},"663d053f51cb4cec934a19fe856d52ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6be7d09cb9c84a0190cee8f390ac63bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6eae93605fd7478c867af6640520dbf0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7063ac1e7c9747abaf8558c6fb498d85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7193a4ed14204de9b2220cf156cf6498":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e01fcbfb0434cff868267315ea45ed2","placeholder":"​","style":"IPY_MODEL_e3161818b024480b96bc6e65119351fc","value":"Map: 100%"}},"73e35f352ac14d3c88be8c7483bb03ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"77885cf419174691b00c2057238d6365":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e1a1fe52acd492da6e0779612ec160d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82fdd095aa8147cb80454ece668ffea2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"952aa671d59d4155af1d23807b64a9fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b42bee723ec4f9d9d19a1b6472fae7b","placeholder":"​","style":"IPY_MODEL_298eb90147cb4b06aae645c73d6821b7","value":" 10000/10000 [00:58&lt;00:00, 168.43 examples/s]"}},"9dcaa58fda0d4bef858299860fe88bac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa0d5b481a5842179097bbe84e85cae7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55b859e84fa44d6ba202aacb3e44ed2f","placeholder":"​","style":"IPY_MODEL_9dcaa58fda0d4bef858299860fe88bac","value":"100%"}},"b01582666abd4a8982fa718aac453856":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58d0f23171214dc4b9e8c29cae828fc7","placeholder":"​","style":"IPY_MODEL_6eae93605fd7478c867af6640520dbf0","value":" 3/3 [00:02&lt;00:00,  2.02it/s]"}},"bf153deb761947f1b148cda002103a05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb7b123873c84ec5a0ce632f4cbc8efb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"cc356df22d3344cca2898d7318fe9c69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03df46fcd67e4ec9ace9ce7c2ac3b323","IPY_MODEL_4e5bcd700f8f4597a77c056015d88686","IPY_MODEL_952aa671d59d4155af1d23807b64a9fd"],"layout":"IPY_MODEL_f1245af2c7ce467799d2a96d04c4a8de"}},"db5e8e76c0794448803c4f4c73e3783c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01acaeca4ff94a01a8fdd1d8edde0b40","IPY_MODEL_de3b0f8544914b8baf739658795efa6e","IPY_MODEL_df01b32650724a399d3f5efa4dfb8117"],"layout":"IPY_MODEL_73e35f352ac14d3c88be8c7483bb03ff"}},"de3b0f8544914b8baf739658795efa6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1daf4473a8b246b6b0929f16c613a8c6","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_663d053f51cb4cec934a19fe856d52ed","value":1000}},"df01b32650724a399d3f5efa4dfb8117":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a97e465628a4867b44b3abd4466aa97","placeholder":"​","style":"IPY_MODEL_7e1a1fe52acd492da6e0779612ec160d","value":" 1000/1000 [00:05&lt;00:00, 152.17 examples/s]"}},"e3161818b024480b96bc6e65119351fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e68a6464e7af4492b6497afd60868881":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_250245c3a4ef4e5aba91157bd1bb4b70","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3d5354f7e5614f5cbf50c02568f81c02","value":3}},"efeecc4f77e049b7965dcb2562ba0c8c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1245af2c7ce467799d2a96d04c4a8de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"!pip install datasets -qq\n!pip install transformers -qq\n!pip install rouge_score evaluate nltk -qq","metadata":{"id":"cejutK-z6GUq","execution":{"iopub.status.busy":"2023-03-19T12:56:48.301689Z","iopub.execute_input":"2023-03-19T12:56:48.301978Z","iopub.status.idle":"2023-03-19T12:57:21.825126Z","shell.execute_reply.started":"2023-03-19T12:56:48.301950Z","shell.execute_reply":"2023-03-19T12:57:21.823775Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport datasets\nimport nltk\nimport evaluate\n\nfrom transformers import (\n    AutoModelForSeq2SeqLM,\n    AutoTokenizer,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n    DataCollatorForSeq2Seq,\n)\n\nfrom collections import Counter\nimport matplotlib.pyplot as plt","metadata":{"id":"l6DAquVeoevc","execution":{"iopub.status.busy":"2023-03-19T12:57:21.828250Z","iopub.execute_input":"2023-03-19T12:57:21.828669Z","iopub.status.idle":"2023-03-19T12:57:34.363385Z","shell.execute_reply.started":"2023-03-19T12:57:21.828624Z","shell.execute_reply":"2023-03-19T12:57:34.362202Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Load dataset","metadata":{"id":"WSiY7Ng-x12F"}},{"cell_type":"code","source":"# load full xsum dataset\ntrain_dataset, dev_dataset, test_dataset = datasets.load_dataset(\"xsum\",split=['train[:10000]', 'validation[:1000]', 'test[:1000]'])\nxsum = datasets.DatasetDict({\n    'train': train_dataset,\n    'validation': dev_dataset,\n    'test': test_dataset,\n})","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["648d2606a4cb4692acd93aaab2ea4167","aa0d5b481a5842179097bbe84e85cae7","e68a6464e7af4492b6497afd60868881","b01582666abd4a8982fa718aac453856","77885cf419174691b00c2057238d6365","55b859e84fa44d6ba202aacb3e44ed2f","9dcaa58fda0d4bef858299860fe88bac","250245c3a4ef4e5aba91157bd1bb4b70","3d5354f7e5614f5cbf50c02568f81c02","58d0f23171214dc4b9e8c29cae828fc7","6eae93605fd7478c867af6640520dbf0"]},"id":"1cCmRsjXohgw","outputId":"9d59697f-b3e5-4db8-b9e8-f1a8e0cae9d8","execution":{"iopub.status.busy":"2023-03-19T13:29:46.701969Z","iopub.execute_input":"2023-03-19T13:29:46.702421Z","iopub.status.idle":"2023-03-19T13:29:47.191005Z","shell.execute_reply.started":"2023-03-19T13:29:46.702383Z","shell.execute_reply":"2023-03-19T13:29:47.190131Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5baac43b09a14ef6aa272f0d3bb614de"}},"metadata":{}}]},{"cell_type":"code","source":"xsum","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d70RLvZwr5ZL","outputId":"307941f8-ba5b-4940-cccb-88342b9aa7e8","execution":{"iopub.status.busy":"2023-03-19T12:59:07.122341Z","iopub.execute_input":"2023-03-19T12:59:07.122876Z","iopub.status.idle":"2023-03-19T12:59:07.142178Z","shell.execute_reply.started":"2023-03-19T12:59:07.122839Z","shell.execute_reply":"2023-03-19T12:59:07.139828Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['document', 'summary', 'id'],\n        num_rows: 204045\n    })\n    validation: Dataset({\n        features: ['document', 'summary', 'id'],\n        num_rows: 11332\n    })\n    test: Dataset({\n        features: ['document', 'summary', 'id'],\n        num_rows: 11334\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"xsum[\"validation\"][0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVSnehZMvXNz","outputId":"6c514c13-28c5-4b9a-ad62-68c6072f157a","execution":{"iopub.status.busy":"2023-03-19T12:59:07.144336Z","iopub.execute_input":"2023-03-19T12:59:07.145133Z","iopub.status.idle":"2023-03-19T12:59:07.157935Z","shell.execute_reply.started":"2023-03-19T12:59:07.145053Z","shell.execute_reply":"2023-03-19T12:59:07.156654Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'document': 'The ex-Reading defender denied fraudulent trading charges relating to the Sodje Sports Foundation - a charity to raise money for Nigerian sport.\\nMr Sodje, 37, is jointly charged with elder brothers Efe, 44, Bright, 50 and Stephen, 42.\\nAppearing at the Old Bailey earlier, all four denied the offence.\\nThe charge relates to offences which allegedly took place between 2008 and 2014.\\nSam, from Kent, Efe and Bright, of Greater Manchester, and Stephen, from Bexley, are due to stand trial in July.\\nThey were all released on bail.',\n 'summary': 'Former Premier League footballer Sam Sodje has appeared in court alongside three brothers accused of charity fraud.',\n 'id': '38295789'}"},"metadata":{}}]},{"cell_type":"code","source":"xsum[\"validation\"].features","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VXrmjRK9zCym","outputId":"9343f31a-dbcd-4d92-950a-5472faf3d23b","execution":{"iopub.status.busy":"2023-03-19T12:59:07.163450Z","iopub.execute_input":"2023-03-19T12:59:07.164360Z","iopub.status.idle":"2023-03-19T12:59:07.174553Z","shell.execute_reply.started":"2023-03-19T12:59:07.164311Z","shell.execute_reply":"2023-03-19T12:59:07.173422Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'document': Value(dtype='string', id=None),\n 'summary': Value(dtype='string', id=None),\n 'id': Value(dtype='string', id=None)}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Load pretrained BART and tokenizer","metadata":{"id":"h3lzVnw_x72v"}},{"cell_type":"code","source":"model_name = 'facebook/bart-base'\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"id":"8Z-00EpAwFN-","execution":{"iopub.status.busy":"2023-03-19T12:59:07.176073Z","iopub.execute_input":"2023-03-19T12:59:07.178920Z","iopub.status.idle":"2023-03-19T12:59:19.033301Z","shell.execute_reply.started":"2023-03-19T12:59:07.178875Z","shell.execute_reply":"2023-03-19T12:59:19.032229Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bab97661ab345a9b0fc404a97ab0e74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7ffc6223cc746e5a733dd8cc09956c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3eaa5017c9843bcb34df9a365b15754"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbbaeb12bd81459892be862e2dbf4279"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2777341730604122b449bc280053baa2"}},"metadata":{}}]},{"cell_type":"code","source":"print(model.config)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T12:59:19.034609Z","iopub.execute_input":"2023-03-19T12:59:19.034961Z","iopub.status.idle":"2023-03-19T12:59:19.042747Z","shell.execute_reply.started":"2023-03-19T12:59:19.034926Z","shell.execute_reply":"2023-03-19T12:59:19.040910Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"BartConfig {\n  \"_name_or_path\": \"facebook/bart-base\",\n  \"activation_dropout\": 0.1,\n  \"activation_function\": \"gelu\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"BartModel\"\n  ],\n  \"attention_dropout\": 0.1,\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.1,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 768,\n  \"decoder_attention_heads\": 12,\n  \"decoder_ffn_dim\": 3072,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"early_stopping\": true,\n  \"encoder_attention_heads\": 12,\n  \"encoder_ffn_dim\": 3072,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_position_embeddings\": 1024,\n  \"model_type\": \"bart\",\n  \"no_repeat_ngram_size\": 3,\n  \"normalize_before\": false,\n  \"normalize_embedding\": true,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 1,\n  \"scale_embedding\": false,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"length_penalty\": 1.0,\n      \"max_length\": 128,\n      \"min_length\": 12,\n      \"num_beams\": 4\n    },\n    \"summarization_cnn\": {\n      \"length_penalty\": 2.0,\n      \"max_length\": 142,\n      \"min_length\": 56,\n      \"num_beams\": 4\n    },\n    \"summarization_xsum\": {\n      \"length_penalty\": 1.0,\n      \"max_length\": 62,\n      \"min_length\": 11,\n      \"num_beams\": 6\n    }\n  },\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the device to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5SkpTlwl0HHZ","outputId":"37f793ca-c2b4-40f9-e2ed-acc8922997dc","execution":{"iopub.status.busy":"2023-03-19T12:59:19.044290Z","iopub.execute_input":"2023-03-19T12:59:19.044986Z","iopub.status.idle":"2023-03-19T12:59:24.775144Z","shell.execute_reply.started":"2023-03-19T12:59:19.044946Z","shell.execute_reply":"2023-03-19T12:59:24.774065Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"BartForConditionalGeneration(\n  (model): BartModel(\n    (shared): Embedding(50265, 768, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n      (layers): ModuleList(\n        (0): BartEncoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (1): BartEncoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (2): BartEncoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (3): BartEncoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (4): BartEncoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (5): BartEncoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n      (layers): ModuleList(\n        (0): BartDecoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (1): BartDecoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (2): BartDecoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (3): BartDecoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (4): BartDecoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (5): BartDecoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"print(f\"BART base size: {np.round(model.num_parameters()/1e6, 1)} M parameters\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUmXMVN00RV_","outputId":"54ce59cb-12e3-4a05-f4da-b1eeb7488289","execution":{"iopub.status.busy":"2023-03-19T12:59:24.779205Z","iopub.execute_input":"2023-03-19T12:59:24.779493Z","iopub.status.idle":"2023-03-19T12:59:24.787410Z","shell.execute_reply.started":"2023-03-19T12:59:24.779466Z","shell.execute_reply":"2023-03-19T12:59:24.786284Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"BART base size: 139.4 M parameters\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Tokenization","metadata":{"id":"vyF7omgWyH4D"}},{"cell_type":"code","source":"max_input_length = 1024\nmax_target_length = 128","metadata":{"execution":{"iopub.status.busy":"2023-03-19T12:59:24.789196Z","iopub.execute_input":"2023-03-19T12:59:24.790152Z","iopub.status.idle":"2023-03-19T12:59:24.796901Z","shell.execute_reply.started":"2023-03-19T12:59:24.790112Z","shell.execute_reply":"2023-03-19T12:59:24.795885Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n    source, target = batch[\"document\"], batch[\"summary\"]\n    source_tokenized = tokenizer(\n        source, padding=\"max_length\", truncation=True, max_length=max_source_length\n    )\n    target_tokenized = tokenizer(\n        target, padding=\"max_length\", truncation=True, max_length=max_target_length\n    )\n\n    batch = {k: v for k, v in source_tokenized.items()}\n    # Ignore padding in the loss\n    batch[\"labels\"] = [\n        [-100 if token == tokenizer.pad_token_id else token for token in l]\n        for l in target_tokenized[\"input_ids\"]\n    ]\n    return batch","metadata":{"id":"42n9CKB3yKyo","execution":{"iopub.status.busy":"2023-03-19T12:59:24.798416Z","iopub.execute_input":"2023-03-19T12:59:24.798978Z","iopub.status.idle":"2023-03-19T12:59:24.807464Z","shell.execute_reply.started":"2023-03-19T12:59:24.798943Z","shell.execute_reply":"2023-03-19T12:59:24.806321Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = xsum.map(\n    lambda batch: batch_tokenize_preprocess(\n        batch, tokenizer, max_input_length, max_target_length\n    ),\n    batched=True,\n    remove_columns=xsum['train'].column_names,\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T13:29:57.201727Z","iopub.execute_input":"2023-03-19T13:29:57.202773Z","iopub.status.idle":"2023-03-19T13:30:16.139536Z","shell.execute_reply.started":"2023-03-19T13:29:57.202722Z","shell.execute_reply":"2023-03-19T13:30:16.137928Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b33c92780b324872b2310e311bf4a8fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c08f2cc376c14a3cba787094c1181bd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fbac79e0e624ae3918d3bede29bcfc2"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQggV7DC5-oK","outputId":"9b426387-a587-4e65-b8df-480ec93de974","execution":{"iopub.status.busy":"2023-03-19T13:30:16.141804Z","iopub.execute_input":"2023-03-19T13:30:16.142228Z","iopub.status.idle":"2023-03-19T13:30:16.158120Z","shell.execute_reply.started":"2023-03-19T13:30:16.142189Z","shell.execute_reply":"2023-03-19T13:30:16.154383Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 10000\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 1000\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.model_max_length","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YDIecDGR6R-0","outputId":"471438f3-1a47-4c9d-ad6d-f7bab399a1d9","execution":{"iopub.status.busy":"2023-03-19T13:05:33.354906Z","iopub.execute_input":"2023-03-19T13:05:33.355669Z","iopub.status.idle":"2023-03-19T13:05:33.559287Z","shell.execute_reply.started":"2023-03-19T13:05:33.355631Z","shell.execute_reply":"2023-03-19T13:05:33.558201Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"1024"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.vocab_size","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IKs1UtAg6W5L","outputId":"a9e5c038-5d77-4402-8b0f-d779299a730d","execution":{"iopub.status.busy":"2023-03-19T13:05:33.561238Z","iopub.execute_input":"2023-03-19T13:05:33.561868Z","iopub.status.idle":"2023-03-19T13:05:33.569662Z","shell.execute_reply.started":"2023-03-19T13:05:33.561829Z","shell.execute_reply":"2023-03-19T13:05:33.568453Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"50265"},"metadata":{}}]},{"cell_type":"markdown","source":"## Training","metadata":{"id":"xF2WdUBuyB3r"}},{"cell_type":"markdown","source":"### Metrics: ROUGE","metadata":{}},{"cell_type":"code","source":"nltk.download(\"punkt\", quiet=True)\nmetric = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2023-03-19T13:05:33.571194Z","iopub.execute_input":"2023-03-19T13:05:33.571652Z","iopub.status.idle":"2023-03-19T13:05:34.822863Z","shell.execute_reply.started":"2023-03-19T13:05:33.571614Z","shell.execute_reply":"2023-03-19T13:05:34.821958Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46796696c8214ca0be64f129875d7c5c"}},"metadata":{}}]},{"cell_type":"code","source":"def postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n\n    # rougeLSum expects newline after each sentence\n    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Some simple post-processing\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(\n        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n    )\n    # Extract a few results from ROUGE\n    result = {key: value * 100 for key, value in result.items()}\n\n    prediction_lens = [\n        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n    ]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"id":"lBbU6Aju8KFB","execution":{"iopub.status.busy":"2023-03-19T13:05:34.824464Z","iopub.execute_input":"2023-03-19T13:05:34.824834Z","iopub.status.idle":"2023-03-19T13:05:34.836531Z","shell.execute_reply.started":"2023-03-19T13:05:34.824797Z","shell.execute_reply":"2023-03-19T13:05:34.835576Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Training arguments","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T13:05:34.838115Z","iopub.execute_input":"2023-03-19T13:05:34.838521Z","iopub.status.idle":"2023-03-19T13:05:34.846197Z","shell.execute_reply.started":"2023-03-19T13:05:34.838483Z","shell.execute_reply":"2023-03-19T13:05:34.845111Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"results\",\n    num_train_epochs=3,  \n    do_train=True,\n    do_eval=True,\n    per_device_train_batch_size=4,  \n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps = 4,\n    warmup_steps=500,\n    weight_decay=0.1,\n    label_smoothing_factor=0.1,\n    predict_with_generate=True,\n    logging_dir=\"logs\",\n    logging_steps=50,\n    save_total_limit=3,\n    report_to=\"none\"\n)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T13:31:18.271324Z","iopub.execute_input":"2023-03-19T13:31:18.272029Z","iopub.status.idle":"2023-03-19T13:31:18.287561Z","shell.execute_reply.started":"2023-03-19T13:31:18.271989Z","shell.execute_reply":"2023-03-19T13:31:18.286579Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"PyTorch: setting up devices\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Train","metadata":{}},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1RBSXX4a7PCP","outputId":"995c6a91-f7f3-4e54-9051-57faf7394e05","execution":{"iopub.status.busy":"2023-03-19T13:31:21.415470Z","iopub.execute_input":"2023-03-19T13:31:21.416356Z","iopub.status.idle":"2023-03-19T14:16:10.273805Z","shell.execute_reply.started":"2023-03-19T13:31:21.416314Z","shell.execute_reply":"2023-03-19T14:16:10.272744Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"***** Running training *****\n  Num examples = 10000\n  Num Epochs = 3\n  Instantaneous batch size per device = 4\n  Total train batch size (w. parallel, distributed & accumulation) = 16\n  Gradient Accumulation steps = 4\n  Total optimization steps = 1875\n  Number of trainable parameters = 139420416\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1875/1875 44:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>4.035700</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>3.966500</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>3.860500</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>3.891700</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>3.833100</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>3.836400</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>3.768500</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.777500</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>3.758700</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>3.728000</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>3.735900</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.673100</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>3.615300</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>3.499900</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>3.513800</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>3.497900</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>3.496200</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>3.498200</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>3.454100</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.459400</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>3.503000</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>3.412500</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>3.449800</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>3.468600</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>3.419900</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>3.237200</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>3.205600</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>3.242400</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>3.218900</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>3.220500</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>3.241500</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>3.205000</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>3.253300</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>3.203500</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>3.205200</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>3.204000</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>3.201800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to results/checkpoint-500\nConfiguration saved in results/checkpoint-500/config.json\nConfiguration saved in results/checkpoint-500/generation_config.json\nModel weights saved in results/checkpoint-500/pytorch_model.bin\ntokenizer config file saved in results/checkpoint-500/tokenizer_config.json\nSpecial tokens file saved in results/checkpoint-500/special_tokens_map.json\nSaving model checkpoint to results/checkpoint-1000\nConfiguration saved in results/checkpoint-1000/config.json\nConfiguration saved in results/checkpoint-1000/generation_config.json\nModel weights saved in results/checkpoint-1000/pytorch_model.bin\ntokenizer config file saved in results/checkpoint-1000/tokenizer_config.json\nSpecial tokens file saved in results/checkpoint-1000/special_tokens_map.json\nSaving model checkpoint to results/checkpoint-1500\nConfiguration saved in results/checkpoint-1500/config.json\nConfiguration saved in results/checkpoint-1500/generation_config.json\nModel weights saved in results/checkpoint-1500/pytorch_model.bin\ntokenizer config file saved in results/checkpoint-1500/tokenizer_config.json\nSpecial tokens file saved in results/checkpoint-1500/special_tokens_map.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1875, training_loss=3.504050118001302, metrics={'train_runtime': 2688.7959, 'train_samples_per_second': 11.157, 'train_steps_per_second': 0.697, 'total_flos': 1.82920937472e+16, 'train_loss': 3.504050118001302, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-03-19T14:26:43.978951Z","iopub.execute_input":"2023-03-19T14:26:43.979389Z","iopub.status.idle":"2023-03-19T14:28:35.256240Z","shell.execute_reply.started":"2023-03-19T14:26:43.979354Z","shell.execute_reply":"2023-03-19T14:28:35.255158Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 1000\n  Batch size = 4\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [250/250 01:48]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Generate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\nGenerate config GenerationConfig {\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 2,\n  \"early_stopping\": true,\n  \"eos_token_id\": 2,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"no_repeat_ngram_size\": 3,\n  \"num_beams\": 4,\n  \"pad_token_id\": 1,\n  \"transformers_version\": \"4.26.1\"\n}\n\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 3.34855318069458,\n 'eval_rouge1': 35.1931,\n 'eval_rouge2': 13.7162,\n 'eval_rougeL': 28.4343,\n 'eval_rougeLsum': 28.4329,\n 'eval_gen_len': 19.58,\n 'eval_runtime': 111.2625,\n 'eval_samples_per_second': 8.988,\n 'eval_steps_per_second': 2.247,\n 'epoch': 3.0}"},"metadata":{}}]},{"cell_type":"code","source":"def generate_summary(test_samples, model):\n    inputs = tokenizer(\n        test_samples[\"document\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=max_input_length,\n        return_tensors=\"pt\",\n    )\n    input_ids = inputs.input_ids.to(model.device)\n    attention_mask = inputs.attention_mask.to(model.device)\n    outputs = model.generate(input_ids, attention_mask=attention_mask)\n    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    return outputs, output_str","metadata":{"id":"fk554nHW_P2p","execution":{"iopub.status.busy":"2023-03-19T13:28:04.825381Z","iopub.status.idle":"2023-03-19T13:28:04.826152Z","shell.execute_reply.started":"2023-03-19T13:28:04.825878Z","shell.execute_reply":"2023-03-19T13:28:04.825904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()","metadata":{"execution":{"iopub.status.busy":"2023-03-19T14:30:00.370307Z","iopub.execute_input":"2023-03-19T14:30:00.371347Z","iopub.status.idle":"2023-03-19T14:30:00.402773Z","shell.execute_reply.started":"2023-03-19T14:30:00.371306Z","shell.execute_reply":"2023-03-19T14:30:00.401766Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08c8aa5be4b24ddfb6486d945cbe4b8e"}},"metadata":{}}]},{"cell_type":"code","source":"model.push_to_hub(\"harouzie/bart-base-xsum\")","metadata":{"execution":{"iopub.status.busy":"2023-03-19T14:31:16.326312Z","iopub.execute_input":"2023-03-19T14:31:16.327962Z","iopub.status.idle":"2023-03-19T14:31:38.741973Z","shell.execute_reply.started":"2023-03-19T14:31:16.327896Z","shell.execute_reply":"2023-03-19T14:31:38.739651Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"Configuration saved in /tmp/tmpl0lmg0_9/config.json\nConfiguration saved in /tmp/tmpl0lmg0_9/generation_config.json\nModel weights saved in /tmp/tmpl0lmg0_9/pytorch_model.bin\nUploading the following files to harouzie/bart-base-xsum: pytorch_model.bin,generation_config.json,config.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01b721065ca14bb58ccc17cfe30f5b95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99299a12a9db45b1bf0f7c8e02d3582c"}},"metadata":{}},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/harouzie/bart-base-xsum/commit/d433fa26c9b9e70770b77436d8db76a19507c014', commit_message='Upload BartForConditionalGeneration', commit_description='', oid='d433fa26c9b9e70770b77436d8db76a19507c014', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.push_to_hub(\"harouzie/bart-base-xsum\")","metadata":{"execution":{"iopub.status.busy":"2023-03-19T14:31:42.280984Z","iopub.execute_input":"2023-03-19T14:31:42.282057Z","iopub.status.idle":"2023-03-19T14:31:44.825435Z","shell.execute_reply.started":"2023-03-19T14:31:42.282003Z","shell.execute_reply":"2023-03-19T14:31:44.824428Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"tokenizer config file saved in /tmp/tmpyjhtj_bn/tokenizer_config.json\nSpecial tokens file saved in /tmp/tmpyjhtj_bn/special_tokens_map.json\nUploading the following files to harouzie/bart-base-xsum: merges.txt,special_tokens_map.json,tokenizer.json,tokenizer_config.json,vocab.json\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/harouzie/bart-base-xsum/commit/4e32594426e3bd7228efc84b4c8238b6cd0fdcd9', commit_message='Upload tokenizer', commit_description='', oid='4e32594426e3bd7228efc84b4c8238b6cd0fdcd9', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}