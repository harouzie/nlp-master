{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMAX6nJDb8a5",
        "outputId": "53b96597-c6b9-40f4-ce52-cd4a609dca75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n"
          ]
        }
      ],
      "source": [
        "# đọc file\n",
        "filename='train.txt'\n",
        "lines=[]\n",
        "count=0\n",
        "#Max=-1\n",
        "Max=10000\n",
        "with open(filename,'r') as f:\n",
        "    for s in f:\n",
        "        count+=1\n",
        "        if count>Max and Max!=-1:\n",
        "            break\n",
        "        lines.append(s.strip())\n",
        "print(len(lines))\n",
        "#print(lines[:5])          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8frJsZqwcWwx",
        "outputId": "03960db1-740d-4baa-b39e-f2374a1e3c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are two reasons companies fail: they only do more of the same, or they only do what's new\n",
            "To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation\n",
            "Both are necessary, but it can be too much of a good thing\n",
            "Consider Facit\n",
            "I'm actually old enough to remember them\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "  print(lines[i])  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9ZOit9Vcswp",
        "outputId": "66f97a1b-7adf-426b-daf6-90d60c9e0072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNwf6LRKb8a9",
        "outputId": "f92d95db-01ae-46aa-90ac-c15ab3499a0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all_tokens_count= 185921\n",
            "10000\n",
            "[['<s>', 'here', 'are', 'two', 'reasons', 'companies', 'fail', ':', 'they', 'only', 'do', 'more', 'of', 'the', 'same', ',', 'or', 'they', 'only', 'do', 'what', \"'s\", 'new', '</s>'], ['<s>', 'to', 'me', 'the', 'real', ',', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', ':', 'exploration', 'and', 'exploitation', '</s>'], ['<s>', 'both', 'are', 'necessary', ',', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing', '</s>'], ['<s>', 'consider', 'facit', '</s>'], ['<s>', 'i', \"'m\", 'actually', 'old', 'enough', 'to', 'remember', 'them', '</s>']]\n"
          ]
        }
      ],
      "source": [
        "# tokenize sentences \n",
        "import nltk\n",
        "sentences=[]\n",
        "all_tokens_count=0\n",
        "for line in lines:\n",
        "    tokens = nltk.word_tokenize(line.lower())\n",
        "    all_tokens_count+=len(tokens)\n",
        "    #sentences.append(tokens)\n",
        "    sentences.append(['<s>']+tokens+['</s>'])\n",
        "print('all_tokens_count=',all_tokens_count)\n",
        "print(len(sentences))\n",
        "print(sentences[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1cCpCzHb8a9",
        "outputId": "6955ca80-1a9b-4a59-a66b-66413462b0cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "V= 12839\n",
            "n= 185921\n",
            "8142\n",
            "418\n"
          ]
        }
      ],
      "source": [
        "# counting 1-gram \n",
        "from collections import Counter\n",
        "counter_unigram=Counter()\n",
        "for sent in sentences:\n",
        "    counter_unigram.update(sent)\n",
        "V=len(counter_unigram)\n",
        "print('V=',V)\n",
        "n=0\n",
        "for gram in counter_unigram:\n",
        "    n+=counter_unigram[gram]\n",
        "n=n-counter_unigram['<s>']-counter_unigram['</s>']\n",
        "print('n=',n)\n",
        "print(counter_unigram['the'])\n",
        "print(counter_unigram['he'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itNiQ0MIb8a-",
        "outputId": "91f68434-a085-45c1-fa33-295212a57635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('<s>', 'the')\n",
            "('the', 'human')\n",
            "('human', 'body')\n",
            "('body', 'with')\n",
            "('with', 'knew')\n",
            "('knew', 'abilities')\n",
            "('abilities', 'is')\n",
            "('is', 'know')\n",
            "('know', 'longer')\n",
            "('longer', 'a')\n",
            "('a', 'question')\n"
          ]
        }
      ],
      "source": [
        "from nltk import ngrams\n",
        "input_sent='the human body with knew abilities is know longer a question'\n",
        "gram2=ngrams(['<s>']+input_sent.split(),2)\n",
        "for gram in gram2:\n",
        "    print(gram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf0tQu_tb8a-",
        "outputId": "a4a10db2-14ac-4112-afd0-c873fd3de5f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "195921\n",
            "('<s>', 'here')\n",
            "('here', 'are')\n",
            "('are', 'two')\n",
            "bigram number = 80118\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "from nltk import ngrams\n",
        "\n",
        "bi_grams=[]\n",
        "for sent in sentences:\n",
        "    gram2=ngrams(sent,2)\n",
        "    bi_grams.extend(gram2)\n",
        "print(len(bi_grams))\n",
        "\n",
        "for i in range(3):\n",
        "    print(bi_grams[i])\n",
        "\n",
        "counter_bigram = Counter(bi_grams)\n",
        "print('bigram number =',len(counter_bigram))\n",
        "print(counter_bigram[('here','are')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lftZk7Ab8a_",
        "outputId": "ed86614e-6ea3-4588-c78c-5669c9bc8968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "185921\n",
            "('<s>', 'here', 'are')\n",
            "('here', 'are', 'two')\n",
            "('are', 'two', 'reasons')\n",
            "trigram number = 142548\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "tri_grams=[]\n",
        "for sent in sentences:\n",
        "    gram3=ngrams(sent,3)\n",
        "    tri_grams.extend(gram3)\n",
        "print(len(tri_grams))\n",
        "\n",
        "for i in range(3):\n",
        "    print(tri_grams[i])\n",
        "\n",
        "counter_trigram = Counter(tri_grams)\n",
        "print('trigram number =',len(counter_trigram))\n",
        "print(counter_trigram[('here','are','two')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8P64Rsyeb8bA"
      },
      "outputs": [],
      "source": [
        "# tính theo Laplace \n",
        "anpha = 0.001\n",
        "def uni_prob(word):\n",
        "    return max(1,counter_unigram[word])/all_tokens_count\n",
        "def bi_prob(word1,word2):\n",
        "    return (counter_bigram[(word1,word2)]+anpha)/(counter_unigram[word1]+V*anpha)\n",
        "    \n",
        "def tri_prob(word1,word2,word3):\n",
        "    return (counter_trigram[(word1,word2,word3)]+anpha)/(counter_bigram[(word1,word2)]+anpha*V)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJaOwXasb8bC"
      },
      "outputs": [],
      "source": [
        "# tính xác suất của một câu, normalize theo 1 từ \n",
        "def probLM(sent,n):\n",
        "    if n>3 or n<1: # không xét trường hợp này \n",
        "        return 0\n",
        "    tokens=nltk.word_tokenize(sent.lower())\n",
        "    tokens = ['<s>']+tokens\n",
        "    prob=1\n",
        "    for i in range(1,len(tokens)):\n",
        "        if n==1:\n",
        "            prob*=uni_prob(tokens[i])\n",
        "        elif n==2:\n",
        "            prob*=bi_prob(tokens[i-1],tokens[i])\n",
        "        elif n==3:\n",
        "            if i>=2:\n",
        "                prob*=tri_prob(tokens[i-2],tokens[i-1],tokens[i])\n",
        "            else:\n",
        "                prob*=bi_prob(tokens[i-1],tokens[i])\n",
        "    k=len(tokens)-1\n",
        "    return prob**(1/k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOmGZMH-b8bC",
        "outputId": "d8aad586-654e-41b4-bec2-973984f4c99b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n=1\n",
            "prob= 0.0013984311264167914\n",
            "perplexity= 715.0870579964178\n",
            "n=2\n",
            "prob= 0.015576696673651823\n",
            "perplexity= 64.1984639587617\n",
            "n=3\n",
            "prob= 0.027047801941636494\n",
            "perplexity= 36.97158098679483\n"
          ]
        }
      ],
      "source": [
        "sent='the human body with new abilities is no longer a question'\n",
        "#sent='the human body with new from abilities is no longer a question'\n",
        "#sent='A few years back from'\n",
        "print('n=1')\n",
        "pr=probLM(sent,1)\n",
        "print('prob=',pr)\n",
        "print('perplexity=',1/pr)\n",
        "\n",
        "print('n=2')\n",
        "pr=probLM(sent,2)\n",
        "print('prob=',pr)\n",
        "print('perplexity=',1/pr)\n",
        "\n",
        "print('n=3')\n",
        "pr=probLM(sent,3)\n",
        "print('prob=',pr)\n",
        "print('perplexity=',1/pr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1i4Nqaub8bD",
        "outputId": "9e3cd942-310a-4ab5-d1e3-33916d63670b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prob= 0.027047801941636494\n",
            "perplexity= 36.97158098679483\n",
            "prob= 0.0007085628998843219\n",
            "perplexity= 1411.3073097155627\n"
          ]
        }
      ],
      "source": [
        "# kiểm tra xem 2 xâu có xác suất hơn nhau thế nào, ví dụ cho bài toán speech to text\n",
        "sent1='the human body with new abilities is no longer a question'\n",
        "sent2='the human body with knew abilities is know longer a question'\n",
        "pr=probLM(sent1,3)\n",
        "print('prob=',pr)\n",
        "print('perplexity=',1/pr)\n",
        "\n",
        "pr=probLM(sent2,3)\n",
        "print('prob=',pr)\n",
        "print('perplexity=',1/pr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAB2zdjkb8bE",
        "outputId": "950c1b0b-b250-4be0-b89b-bb6b1c20cc0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "stupid back off\n",
            "prob= 0.1174173359939537\n",
            "perplexity sent1= 8.516629946803546\n",
            "prob= 0.003075945626490854\n",
            "perplexity sent2= 325.10327600973716\n",
            "\n",
            "laplace\n",
            "prob= 0.027047801941636494\n",
            "perplexity sent1= 36.97158098679483\n",
            "prob= 0.0007085628998843219\n",
            "perplexity sent2= 1411.3073097155627\n"
          ]
        }
      ],
      "source": [
        "sent1='the human body with new abilities is no longer a question'\n",
        "sent2='the human body with knew abilities is know longer a question'\n",
        "\n",
        "def stp_back_off(sent):\n",
        "  # start with triagram and\n",
        "  tokens=nltk.word_tokenize(sent.lower())\n",
        "  tokens = ['<s>']+tokens\n",
        "  prob=1\n",
        "  for i in range(3,len(tokens)):\n",
        "    if tri_prob(tokens[i-2],tokens[i-1],tokens[i]) == 0:\n",
        "      if bi_prob(tokens[i-1],tokens[i]) == 0:\n",
        "        prob*= 0.4*0.4*uni_prob(tokens[i])\n",
        "      else:\n",
        "        prob*= 0.4*bi_prob(tokens[i-1],tokens[i])\n",
        "    else:\n",
        "      prob*=tri_prob(tokens[i-2],tokens[i-1],tokens[i])\n",
        "  k=len(tokens)-1\n",
        "  return prob**(1/k)\n",
        "\n",
        "# stupid back off implementation\n",
        "print(\"stupid back off\")\n",
        "pr=stp_back_off(sent1)\n",
        "print('prob=',pr)\n",
        "print('perplexity sent1=',1/pr)\n",
        "\n",
        "pr=stp_back_off(sent2)\n",
        "print('prob=',pr)\n",
        "print('perplexity sent2=',1/pr)\n",
        "# laplace \n",
        "print(\"\\nlaplace\")\n",
        "pr=probLM(sent1,3)\n",
        "print('prob=',pr)\n",
        "print('perplexity sent1=',1/pr)\n",
        "\n",
        "pr=probLM(sent2,3)\n",
        "print('prob=',pr)\n",
        "print('perplexity sent2=',1/pr)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "27f6fea6f47ae512550f0b8facdbd035a93e1dd89633f7bf2dd00a2502c71d0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
